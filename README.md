# Hyper-Parameter-Optimization

There are many parameters one can select when building and training a Neural Network in TensorFlow. These are often called Hyper-Parameters. For example, there is a hyper-parameter for how many layers the network should have, and another hyper-parameter for how many nodes per layer, and another hyper-parameter for the activation function to use, etc. The optimization method also has one or more hyper-parameters you can select, such as the learning-rate.

Here in this NoteBook i have used a clever method for finding good hyper-parameters known as Bayesian Optimization.
